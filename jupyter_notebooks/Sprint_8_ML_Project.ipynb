{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review**\n",
    "\n",
    "Hi, my name is Dmitry and I will be reviewing your project.\n",
    "  \n",
    "You can find my comments in colored markdown cells:\n",
    "  \n",
    "<div class=\"alert alert-success\">\n",
    "  If everything is done successfully.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-warning\">\n",
    "  If I have some (optional) suggestions, or questions to think about, or general comments.\n",
    "</div>\n",
    "  \n",
    "<div class=\"alert alert-danger\">\n",
    "  If a section requires some corrections. Work can't be accepted with red comments.\n",
    "</div>\n",
    "  \n",
    "Please don't remove my comments, as it will make further review iterations much harder for me.\n",
    "  \n",
    "Feel free to reply to my comments or ask questions using the following template:\n",
    "  \n",
    "<div class=\"alert alert-info\">\n",
    "  For your comments and questions.\n",
    "</div>\n",
    "  \n",
    "First of all, thank you for turning in the project! You did a great job overall! There are only a couple of small issues that need to be addressed before the project is accepted. Let me know if you have questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Beta Bank has provided data on their clients' past behavior and termination of contracts with the bank. The bank notices that their customers are leaving a little more every month. Because of this, the bankers want to predict whether a customer will be leaving.\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "Using the data collected by Beta Bank, we will perform the following: \n",
    "- Make a prediction model on whether or not a client will terminate their contract with Beta Bank.\n",
    "- The model should achieve the maximum possible F1 score greater than 0.59 on the test set.\n",
    "- Compare the AUC-ROC metric and with the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--<div class=\"alert alert-info\"; style=\"border-left: 7px solid blue\">\n",
    "<b>Student's comment</b>\n",
    "    I'll use this blue box for my comments. Thank you for reviewing my project! \n",
    "</div>-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Data\n",
    "\n",
    "To begin, we will first perform the following on the data:\n",
    "\n",
    "- Load the necessary libraries\n",
    "- Import the file into Dataframes\n",
    "- Display the data\n",
    "- View the info\n",
    "- Adjust data set for unnecessary columns\n",
    "- Check for nulls and fill in, if possible\n",
    "- Check the unique values\n",
    "- Check for duplicates\n",
    "- Encode the data\n",
    "- Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, accuracy_score, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the file into Dataframes\n",
    "try:\n",
    "    df = pd.read_csv('/datasets/Churn.csv', sep=',')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    df = pd.read_csv('../datasets/Churn.csv', sep=',')\n",
    "# data = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was loaded and inspected\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "Features\n",
    "- RowNumber — data string index\n",
    "- CustomerId — unique customer identifier\n",
    "- Surname — surname\n",
    "- CreditScore — credit score\n",
    "- Geography — country of residence\n",
    "- Gender — gender\n",
    "- Age — age\n",
    "- Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "- Balance — account balance\n",
    "- NumOfProducts — number of banking products used by the customer\n",
    "- HasCrCard — customer has a credit card\n",
    "- IsActiveMember — customer’s activeness\n",
    "- EstimatedSalary — estimated salary\n",
    "\n",
    "Target\n",
    "- Exited — сustomer has left (0 = stayed; 1 = exited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of improving our models later on, we see that the columns RowNumber, CustomerId, and Surname should be dropped. These identifiers won't help predict if the clients exit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Makes sense!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0          619    France  Female   42     2.0       0.00              1   \n",
      "1          608     Spain  Female   41     1.0   83807.86              1   \n",
      "2          502    France  Female   42     8.0  159660.80              3   \n",
      "3          699    France  Female   39     1.0       0.00              2   \n",
      "4          850     Spain  Female   43     2.0  125510.82              1   \n",
      "5          645     Spain    Male   44     8.0  113755.78              2   \n",
      "6          822    France    Male   50     7.0       0.00              2   \n",
      "7          376   Germany  Female   29     4.0  115046.74              4   \n",
      "8          501    France    Male   44     4.0  142051.07              2   \n",
      "9          684    France    Male   27     2.0  134603.88              1   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "0          1               1        101348.88       1  \n",
      "1          0               1        112542.58       0  \n",
      "2          1               0        113931.57       1  \n",
      "3          0               0         93826.63       0  \n",
      "4          1               1         79084.10       0  \n",
      "5          1               0        149756.71       1  \n",
      "6          1               1         10062.80       0  \n",
      "7          1               0        119346.88       1  \n",
      "8          0               1         74940.50       0  \n",
      "9          1               1         71725.73       0  \n"
     ]
    }
   ],
   "source": [
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           9091 non-null   float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Geography and Gender are string objects, we will have to encode them to be usable for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "30            591     Spain  Female   39     NaN       0.00              3   \n",
      "48            550   Germany    Male   38     NaN  103391.38              1   \n",
      "51            585   Germany    Male   36     NaN  146050.97              2   \n",
      "53            655   Germany    Male   41     NaN  125561.97              1   \n",
      "60            742   Germany    Male   35     NaN  136857.00              1   \n",
      "...           ...       ...     ...  ...     ...        ...            ...   \n",
      "9944          744   Germany    Male   41     NaN  190409.34              2   \n",
      "9956          520    France  Female   46     NaN   85216.61              1   \n",
      "9964          479    France    Male   34     NaN  117593.48              2   \n",
      "9985          659    France    Male   36     NaN  123841.49              2   \n",
      "9999          792    France  Female   28     NaN  130142.79              1   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
      "30            1               0        140469.38       1  \n",
      "48            0               1         90878.13       0  \n",
      "51            0               0         86424.57       0  \n",
      "53            0               0        164040.94       1  \n",
      "60            0               0         84509.57       0  \n",
      "...         ...             ...              ...     ...  \n",
      "9944          1               1        138361.48       0  \n",
      "9956          1               0        117369.52       1  \n",
      "9964          0               0        113308.29       0  \n",
      "9985          1               0         96833.00       0  \n",
      "9999          1               0         38190.78       0  \n",
      "\n",
      "[909 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[data['Tenure'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's null values in the Tenure column. We will inspect the records with nulls and determine what to do with them since they can possibly effect the models later on. \n",
    "\n",
    "Our options can be to:\n",
    "- use the mean or median to fill in\n",
    "- drop the rows moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.997690023099769\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(data['Tenure'].mean())\n",
    "print(data['Tenure'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the mean and median are so close, we will fill the null values in with the value of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Tenure'].sort_values().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values\n",
    "data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Missing values were dealt with reasonably\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore         460\n",
      "Geography             3\n",
      "Gender                2\n",
      "Age                  70\n",
      "Tenure               11\n",
      "Balance            6382\n",
      "NumOfProducts         4\n",
      "HasCrCard             2\n",
      "IsActiveMember        2\n",
      "EstimatedSalary    9999\n",
      "Exited                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check uniqueness\n",
    "print(data.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [CreditScore, Geography, Gender, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Exited]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(data[data.duplicated()])\n",
    "#print(data[data['CustomerId'].duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Data\n",
    "We saw earlier that Geography and Gender were object string columns. So, we will have to encode them for our models. Similarly, we will change some of the int and float columns into scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0             619   42     2.0       0.00              1          1   \n",
      "1             608   41     1.0   83807.86              1          0   \n",
      "2             502   42     8.0  159660.80              3          1   \n",
      "3             699   39     1.0       0.00              2          0   \n",
      "4             850   43     2.0  125510.82              1          1   \n",
      "...           ...  ...     ...        ...            ...        ...   \n",
      "9995          771   39     5.0       0.00              2          1   \n",
      "9996          516   35    10.0   57369.61              1          1   \n",
      "9997          709   36     7.0       0.00              1          0   \n",
      "9998          772   42     3.0   75075.31              2          1   \n",
      "9999          792   28     5.0  130142.79              1          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
      "0                  1        101348.88       1                  0   \n",
      "1                  1        112542.58       0                  0   \n",
      "2                  0        113931.57       1                  0   \n",
      "3                  0         93826.63       0                  0   \n",
      "4                  1         79084.10       0                  0   \n",
      "...              ...              ...     ...                ...   \n",
      "9995               0         96270.64       0                  0   \n",
      "9996               1        101699.77       0                  0   \n",
      "9997               1         42085.58       1                  0   \n",
      "9998               0         92888.52       1                  1   \n",
      "9999               0         38190.78       0                  0   \n",
      "\n",
      "      Geography_Spain  Gender_Male  \n",
      "0                   0            0  \n",
      "1                   1            0  \n",
      "2                   0            0  \n",
      "3                   0            0  \n",
      "4                   1            0  \n",
      "...               ...          ...  \n",
      "9995                0            1  \n",
      "9996                0            1  \n",
      "9997                0            0  \n",
      "9998                0            1  \n",
      "9999                0            0  \n",
      "\n",
      "[10000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "print(data_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Categorical features were encoded\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_ohe.drop(['Exited'], axis=1)\n",
    "target = data_ohe['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Features and targets were separated\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "We will use the split of 60% training, 20% validation and 20% test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(2000, 11)\n",
      "(2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# First, extract 20% for test set\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=12345\n",
    ")\n",
    "# Next, split the remaining 80% into 60% training and 20% validation sets\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345\n",
    ")\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data split is reasonable\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "492     -0.134048 -0.078068 -0.369113  0.076163              2          0   \n",
      "6655    -1.010798  0.494555 -0.007415  0.136391              1          1   \n",
      "4287     0.639554  1.353490 -1.454209  0.358435              1          1   \n",
      "42      -0.990168  2.116987 -1.092511  0.651725              1          1   \n",
      "8178     0.567351  0.685430  0.715982  0.813110              2          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "492                1         0.331571                  0                0   \n",
      "6655               1        -0.727858                  0                0   \n",
      "4287               1        -0.477006                  1                0   \n",
      "42                 1        -0.100232                  0                0   \n",
      "8178               1         0.801922                  0                0   \n",
      "\n",
      "      Gender_Male  \n",
      "492             0  \n",
      "6655            1  \n",
      "4287            1  \n",
      "42              0  \n",
      "8178            0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65/1681073669.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_test[numeric] = scaler.transform(features_test[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])\n",
    "print(features_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Scaling was applied correctly\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance of Classes\n",
    "\n",
    "Examine the balance of classes. Train the model without taking into account the imbalance. Briefly describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print(data['Exited'].value_counts() / data.shape[0])\n",
    "print(target.value_counts() / data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of customers that exited is about a quarter of the amount who stayed. We will first train the models without taking the imbalance in mind. Then we will incorporate the imbalance later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Distribution of targets was examined\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Optimize Models\n",
    "\n",
    "Improve the quality of the model. Make sure you use at least two approaches to fixing class imbalance. Use the training set to pick the best parameters. Train different models on training and validation sets. Find the best one. Briefly describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to optimize the models\n",
    "\n",
    "def model_optimizer(model_name, dep=0, estim=10, strg=0):\n",
    "    best_model = None\n",
    "    best_est, best_depth, best_valid_f1, best_roc_auc = 0, 0, 0, 0\n",
    "    depth_or_strength = 'Depth'\n",
    "    estimators = estim+1\n",
    "    max_dep = dep+1\n",
    "    if strg != 0:\n",
    "        max_dep = strg\n",
    "        depth_or_strength = 'Strength'\n",
    "    for est in range(10, estimators, 5):\n",
    "        for depth in range(1, max_dep):\n",
    "            # if statements for DecTree, RandFor, LogReg\n",
    "            if model_name == RandomForestClassifier:\n",
    "                model = model_name(random_state=12345, max_depth=depth, n_estimators=est)\n",
    "            elif model_name == LogisticRegression:\n",
    "                model = LogisticRegression(solver='liblinear', C=depth, random_state=12345)\n",
    "            else:\n",
    "                model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "            model.fit(features_train, target_train)\n",
    "            predictions_valid = model.predict(features_valid)\n",
    "            f1_valid = f1_score(target_valid, predictions_valid)\n",
    "            pred_proba_valid = model.predict_proba(features_valid)\n",
    "            proba_one_valid = pred_proba_valid[:, 1]\n",
    "            roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "            if f1_valid > best_valid_f1:\n",
    "                best_est = est\n",
    "                best_depth = depth\n",
    "                best_valid_f1 = f1_valid\n",
    "                best_roc_auc = roc_auc_valid\n",
    "                best_model = model\n",
    "    print('Best', depth_or_strength, ':', best_depth)\n",
    "    print('Best n-estimators', best_est)\n",
    "    print('Best F1 of Validation Set:', best_valid_f1)\n",
    "    print('AUC-ROC of Validation Set:', best_roc_auc)\n",
    "    print(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "\n",
    "1. The test set's purpose is to get an unbiased estimate of the final model's generalization performance after we're done with model selection and hyperparameter tuning using the validation set. That is only possible if the test set is used only once: to evaluate that final model. Please make sure that you only use the validation set to evaluate the models prior to the final testing\n",
    "    \n",
    "2. To calculate ROC-AUC we need slightly different inputs than other metrics. Remember that the ROC curve is constructed by varying the threshold of assigning positive class between 0 and 1. For binary predictions the threshold is predefined, so we need to use 'probabilities' (method `predict_proba` instead of `predict`)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  Adjusted the model optimizer function to find the best results from the validation set and hopefully did the AUC-ROC correctly this time.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "Awesome, all looks good!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth : 11\n",
      "Best n-estimators 35\n",
      "Best F1 of Validation Set: 0.5636070853462157\n",
      "AUC-ROC of Validation Set: 0.8472435262645065\n",
      "RandomForestClassifier(max_depth=11, n_estimators=35, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "model_optimizer(RandomForestClassifier, dep=12, estim=60)  # 10, 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "F1: 0.7556447566482689\n",
      "AUC-ROC: 0.9788052207612199\n",
      "\n",
      "Validation Set:\n",
      "F1: 0.5636070853462157\n",
      "AUC-ROC: 0.8472435262645065\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=35, max_depth=11, random_state=12345) \n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "predictions_train = model.predict(features_train)\n",
    "predictions_valid = model.predict(features_valid)\n",
    "pred_proba_train = model.predict_proba(features_train)\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_train = pred_proba_train[:, 1]\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "\n",
    "print('Train Set:')\n",
    "print('F1:', f1_score(target_train, predictions_train))\n",
    "print('AUC-ROC:', roc_auc_score(target_train, proba_one_train))\n",
    "print()\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, proba_one_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth : 7\n",
      "Best n-estimators 10\n",
      "Best F1 of Validation Set: 0.5583596214511041\n",
      "AUC-ROC of Validation Set: 0.8231010349393358\n",
      "DecisionTreeClassifier(max_depth=7, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "model_optimizer(DecisionTreeClassifier, dep=12)  # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:\n",
      "F1: 0.625754527162978\n",
      "AUC-ROC: 0.8811987188143386\n",
      "\n",
      "Validation Set:\n",
      "F1: 0.5583596214511041\n",
      "AUC-ROC: 0.8231010349393358\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=7, random_state=12345) \n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "predictions_train = model.predict(features_train)\n",
    "predictions_valid = model.predict(features_valid)\n",
    "pred_proba_train = model.predict_proba(features_train)\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_train = pred_proba_train[:, 1]\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "\n",
    "print('Train Set:')\n",
    "print('F1:', f1_score(target_train, predictions_train))\n",
    "print('AUC-ROC:', roc_auc_score(target_train, proba_one_train))\n",
    "print()\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_score(target_valid, predictions_valid))\n",
    "print('AUC-ROC:', roc_auc_score(target_valid, proba_one_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "F1 of Validation Set: 0.0\n",
      "AUC-Roc of Test Set: 0.6904695296120447\n",
      "\n",
      "2\n",
      "F1 of Validation Set: 0.5037037037037037\n",
      "AUC-Roc of Test Set: 0.7396462354498909\n",
      "\n",
      "3\n",
      "F1 of Validation Set: 0.39382239382239387\n",
      "AUC-Roc of Test Set: 0.7938649126794771\n",
      "\n",
      "4\n",
      "F1 of Validation Set: 0.430188679245283\n",
      "AUC-Roc of Test Set: 0.8064340768598627\n",
      "\n",
      "5\n",
      "F1 of Validation Set: 0.5488372093023256\n",
      "AUC-Roc of Test Set: 0.8224509194603883\n",
      "\n",
      "6\n",
      "F1 of Validation Set: 0.5113043478260869\n",
      "AUC-Roc of Test Set: 0.8136862819275844\n",
      "\n",
      "7\n",
      "F1 of Validation Set: 0.5583596214511041\n",
      "AUC-Roc of Test Set: 0.8231010349393358\n",
      "\n",
      "8\n",
      "F1 of Validation Set: 0.5398773006134968\n",
      "AUC-Roc of Test Set: 0.7996889300752322\n",
      "\n",
      "9\n",
      "F1 of Validation Set: 0.5357142857142857\n",
      "AUC-Roc of Test Set: 0.7814086047313784\n",
      "\n",
      "10\n",
      "F1 of Validation Set: 0.5383502170767005\n",
      "AUC-Roc of Test Set: 0.7580608756054101\n",
      "\n",
      "11\n",
      "F1 of Validation Set: 0.5131964809384164\n",
      "AUC-Roc of Test Set: 0.7388991589826408\n",
      "\n",
      "12\n",
      "F1 of Validation Set: 0.508029197080292\n",
      "AUC-Roc of Test Set: 0.72204066321316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 13): \n",
    "    print(depth)\n",
    "    model_dtc = DecisionTreeClassifier(random_state=12345, max_depth=depth) # min_samples_split, max_depth\n",
    "    model_dtc.fit(features_train, target_train) # train model on training set\n",
    "    predictions_valid_dtc = model_dtc.predict(features_valid) # get model predictions on validation set\n",
    "    f1_valid = f1_score(target_valid, predictions_valid_dtc)\n",
    "    print('F1 of Validation Set:', f1_valid)\n",
    "    pred_proba_valid = model_dtc.predict_proba(features_valid)\n",
    "    proba_one_valid = pred_proba_valid[:, 1]\n",
    "    r_a_score = roc_auc_score(target_valid, proba_one_valid)\n",
    "    print('AUC-Roc of Test Set:', r_a_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Strength : 8\n",
      "Best n-estimators 10\n",
      "Best F1 of Validation Set: 0.30451127819548873\n",
      "AUC-ROC of Validation Set: 0.7703200825281067\n",
      "LogisticRegression(C=8, random_state=12345, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "model_optimizer(LogisticRegression, strg=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Strength: 8\n",
      "Best F1 of Validation Set: 0.30451127819548873\n",
      "LogisticRegression(C=8, random_state=12345, solver='liblinear')\n",
      "AUC-ROC: 0.7703200825281067\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression \n",
    "# Double checking the optimizer\n",
    "best_model = None\n",
    "best_strength, best_f1_valid, best_r_a_valid = 0, 0, 0 # best_rmse, \n",
    "print('LogisticRegression')\n",
    "# for est in range(10, 51, 10):\n",
    "for strength in range (1, 11):\n",
    "    model_lgr = LogisticRegression(solver='liblinear', C=strength, random_state=12345)\n",
    "    model_lgr.fit(features_train, target_train)\n",
    "    predictions_valid_lgr = model_lgr.predict(features_valid)\n",
    "    f1_valid_lgr = f1_score(target_valid, predictions_valid_lgr)\n",
    "    \n",
    "    pred_proba_valid = model_lgr.predict_proba(features_valid)\n",
    "    proba_one_valid = pred_proba_valid[:, 1]\n",
    "    roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "    if f1_valid_lgr > best_f1_valid:\n",
    "        best_f1_valid = f1_valid_lgr\n",
    "        best_strength = strength\n",
    "        best_model = model_lgr\n",
    "        best_r_a_valid = roc_auc_valid\n",
    "print('Strength:', best_strength)\n",
    "print('Best F1 of Validation Set:', best_f1_valid)\n",
    "print(best_model)\n",
    "print('AUC-ROC:', best_r_a_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "RMSE is a regression metric and is not very useful in a classification context\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Removed the RMSE metric and updated the AUC-ROC code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without balancing the classes, the RandomForestClassifier had the best F1 and AUC-ROC scores, followed closely by the DecisionTreeClassifier model in both scores. The Logistic Regression model performed the weakest. However, none of the models were able to reach our F1 target of 0.59, which leads us to try balancing the classes.\n",
    "\n",
    "Moving forward, we will balance the classes with upsampling and downsampling. Then, we will rerun our optimized RandomForestClassifier with the parameters of max_depth of 11 and n_estimators at 35, and DecisionTreeClassifier with the max_depth of 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Alright, you trained a couple of models without taking the imbalance into account firfst\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Updated the findings in this section.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "Great!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsampling and Downsampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of values for customers who stayed is about four times the amount of customers that exited, we will employ upsampling and downsampling to try and improve the chosen models from the previous section. Our results will be compared after both balanced sets have been modeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9657, 11)\n",
      "(9657,)\n",
      "1    0.504919\n",
      "0    0.495081\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Upsampling\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(\n",
    "    features_train, target_train, 4\n",
    ")\n",
    "\n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)\n",
    "print(target_upsampled.value_counts() / target_upsampled.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2414, 11)\n",
      "(2414,)\n",
      "1    0.504971\n",
      "0    0.495029\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Downsampling\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.25\n",
    ")\n",
    "\n",
    "print(features_downsampled.shape)\n",
    "print(target_downsampled.shape)\n",
    "print(target_downsampled.value_counts() / target_downsampled.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Upsampling and downsampling were correctly applied only to the train set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Testing \n",
    "\n",
    "With our upsampled and downsampled data, we will use the models found earlier to be the most optimized on these new data sets and compare results to narrow down which model we will employ in the final test. \n",
    "\n",
    "The first four sets of code will help us choose the final model for our test set. We will use the RandomForestClassifier with the parameters of max_depth of 11 and n_estimators at 35, and DecisionTreeClassifier with the max_depth of 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampled Set Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set:\n",
      "F1: 0.5549949545913219\n",
      "AUC-ROC: 0.8083621699551278\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree with the upsampled set\n",
    "model = DecisionTreeClassifier(max_depth=7, random_state=12345) \n",
    "\n",
    "model.fit(features_upsampled, target_upsampled) # upsampled set\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1_valid = f1_score(target_valid, predictions_valid)\n",
    "\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_valid)\n",
    "print('AUC-ROC:', roc_auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set:\n",
      "F1: 0.5885111371629542\n",
      "AUC-ROC: 0.8432856105124785\n"
     ]
    }
   ],
   "source": [
    "# RandomForest upsample\n",
    "model = RandomForestClassifier(n_estimators=35, max_depth=11, random_state=12345) \n",
    "\n",
    "model.fit(features_upsampled, target_upsampled) # upsampled set\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1_valid = f1_score(target_valid, predictions_valid)\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_valid)\n",
    "print('AUC-ROC:', roc_auc_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampled Set Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set:\n",
      "F1: 0.5493482309124766\n",
      "AUC-ROC: 0.8143546769371137\n"
     ]
    }
   ],
   "source": [
    "# Train with the downsampled set\n",
    "model = DecisionTreeClassifier(max_depth=7, random_state=12345) \n",
    "\n",
    "model.fit(features_downsampled, target_downsampled) # downsampled set\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1_valid = f1_score(target_valid, predictions_valid)\n",
    "\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_valid)\n",
    "print('AUC-ROC:', roc_auc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set:\n",
      "F1: 0.5612343297974928\n",
      "AUC-ROC: 0.8379241447166592\n"
     ]
    }
   ],
   "source": [
    "# RandomForest with the downsampled set\n",
    "model = RandomForestClassifier(n_estimators=35, max_depth=11, random_state=12345) \n",
    "\n",
    "model.fit(features_downsampled, target_downsampled) # downsampled set\n",
    "predictions_valid = model.predict(features_valid)\n",
    "f1_valid = f1_score(target_valid, predictions_valid)\n",
    "pred_proba_valid = model.predict_proba(features_valid)\n",
    "proba_one_valid = pred_proba_valid[:, 1]\n",
    "roc_auc_valid = roc_auc_score(target_valid, proba_one_valid)\n",
    "\n",
    "print('Validation Set:')\n",
    "print('F1:', f1_valid)\n",
    "print('AUC-ROC:', roc_auc_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "I would suggest first selecting the balancing technique using the validation set, and only then evaluating the best model using the test set to avoid any bias\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Updated the previous code to use only the validation sets and made a seperate section below to run the best model on the test set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "Very good!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model on Test Set\n",
    "\n",
    "Now that we found that RandomForestClassifier, with the parameters of max_depth of 11 and n_estimators at 35, gave the best F1 and AUC-ROC scores on the upsampled set, we will run the model on our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "F1: 0.6358635863586358\n",
      "AUC-ROC: 0.8602217454676471\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with the upsampled set for final testing\n",
    "model = RandomForestClassifier(n_estimators=35, max_depth=11, random_state=12345) \n",
    "\n",
    "model.fit(features_upsampled, target_upsampled) # upsampled set\n",
    "predictions_test = model.predict(features_test) # Test sets\n",
    "f1_test = f1_score(target_test, predictions_test)\n",
    "\n",
    "pred_proba_test = model.predict_proba(features_test)\n",
    "proba_one_test = pred_proba_test[:, 1]\n",
    "roc_auc_test = roc_auc_score(target_test, proba_one_test)\n",
    "\n",
    "print('Test Set:')\n",
    "print('F1:', f1_test)\n",
    "print('AUC-ROC:', roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "Excellent, the model beats the F1 score threshold when evaluated on unseen data :)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "<!-- - How did you prepare the data for training? Have you processed all of the feature types?\n",
    "- Have you explained the preprocessing steps well enough?\n",
    "- How did you investigate the balance of classes?\n",
    "- Did you study the model without taking into account the imbalance of classes?\n",
    "- What are your findings about the task research?\n",
    "- Have you correctly split the data into sets?\n",
    "- How have you worked with the imbalance of classes?\n",
    "- Did you use at least two techniques for imbalance fixing?\n",
    "- Have you performed the model training, validation, and final testing correctly?\n",
    "- How high is your F1 score?\n",
    "- Did you examine the AUC-ROC values?\n",
    "- Have you kept to the project structure and kept the code neat?\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta Bank should use the upsampled data to prevent an imbalance of classes. Before using either upsampled or downsampled data, none of our optimized models on the original data had beaten our minimum F1 score of 0.59. \n",
    "\n",
    "The F1 score of 0.636, which beat our original benchmark of 0.59, was achieved by upsampling our data and using the RandomForestClassifier with the n_estimators=35 and max_depth=11 as attributes. This model also produced an AUC-ROC score of 0.860.\n",
    "\n",
    "Across the different models, Beta Bank should use the RandomForestClassifier model on the upsampled data to determine if a customer is going to terminate their contract or stay with Beta Bank.\n",
    "\n",
    "<!--The AUC-ROC scores among all models, balanced and imbalanced, did beat the base ROC score of 0.5, which was a sanity check in itself. Both the F1 and AUC-ROC scores went up when using both balanced sets. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<s><b>Reviewer's comment</b>\n",
    "\n",
    "Please check the conclusions after fixing the problems above\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Updated the conclusion with new results.\n",
    "    Thank you for taking the time to review and give helpful feedback!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment V2</b>\n",
    "\n",
    "You're welcome! :)\n",
    "    \n",
    "The project is now accepted. Keep up the good work on the next sprint!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
